2025-06-15 22:12:34,030 INFO - Task context logging is enabled
2025-06-15 22:12:34,036 INFO - Loaded executor: SequentialExecutor
2025-06-15 22:12:34,146 INFO - Starting the scheduler
2025-06-15 22:12:34,147 INFO - Processing each file at most -1 times
2025-06-15 22:12:34,153 INFO - Launched DagFileProcessorManager with pid: 75545
2025-06-15 22:12:34,155 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:14:23,590 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:14:23,591 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:14:23,591 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:14:23,594 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-15 22:14:23,595 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T18:14:19+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-15 22:14:23,596 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:14:23,598 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:14:28,038 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T18:14:19+00:00', try_number=1, map_index=-1)
2025-06-15 22:14:28,051 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:14:27.330037+00:00, run_end_date=2025-06-15 18:14:27.507066+00:00, run_duration=0.177029, state=success, executor_state=success, try_number=1, max_tries=2, job_id=2, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2025-06-15 18:14:23.592936+00:00, queued_by_job_id=1, pid=75659
2025-06-15 22:14:28,107 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:14:28,107 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:14:28,108 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:14:28,110 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-15 22:14:28,111 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2025-06-15 22:14:28,112 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:14:28,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:14:32,563 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=1, map_index=-1)
2025-06-15 22:14:32,571 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:14:31.833200+00:00, run_end_date=2025-06-15 18:14:32.037375+00:00, run_duration=0.204175, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=3, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-06-15 18:14:28.109704+00:00, queued_by_job_id=1, pid=75681
2025-06-15 22:17:34,218 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:19:32,495 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:19:32,496 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:19:32,497 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:19:32,499 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=2, map_index=-1) to executor with priority 6 and queue default
2025-06-15 22:19:32,500 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:19:32,502 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:19:36,915 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=2, map_index=-1)
2025-06-15 22:19:36,925 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:19:36.204510+00:00, run_end_date=2025-06-15 18:19:36.366682+00:00, run_duration=0.162172, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=4, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-06-15 18:19:32.498130+00:00, queued_by_job_id=1, pid=75820
2025-06-15 22:22:34,271 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:24:36,784 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:24:36,785 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:24:36,786 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:24:36,788 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=3, map_index=-1) to executor with priority 6 and queue default
2025-06-15 22:24:36,789 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:24:36,791 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:24:41,266 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=3, map_index=-1)
2025-06-15 22:24:41,275 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:24:40.519917+00:00, run_end_date=2025-06-15 18:24:40.675548+00:00, run_duration=0.155631, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=5, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-06-15 18:24:36.787212+00:00, queued_by_job_id=1, pid=75966
2025-06-15 22:24:43,699 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:24:43,700 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:24:43,700 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:24:43,703 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-15 22:24:43,704 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:14:19+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-15 22:24:43,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:24:43,706 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:24:47,931 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:14:19+00:00', try_number=1, map_index=-1)
2025-06-15 22:24:47,940 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:24:47.228674+00:00, run_end_date=2025-06-15 18:24:47.396214+00:00, run_duration=0.16754, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 18:24:43.701919+00:00, queued_by_job_id=1, pid=75969
2025-06-15 22:27:34,333 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:29:47,436 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:29:47,437 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:29:47,438 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:29:47,440 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:14:19+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2025-06-15 22:29:47,441 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:29:47,443 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:29:51,837 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:14:19+00:00', try_number=2, map_index=-1)
2025-06-15 22:29:51,846 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:29:51.140203+00:00, run_end_date=2025-06-15 18:29:51.307268+00:00, run_duration=0.167065, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 18:29:47.439558+00:00, queued_by_job_id=1, pid=76048
2025-06-15 22:32:34,298 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:34:51,494 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:34:51,495 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:34:51,496 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 22:34:51,498 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:14:19+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2025-06-15 22:34:51,499 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:34:51,501 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:34:55,995 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:14:19+00:00', try_number=3, map_index=-1)
2025-06-15 22:34:56,003 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 18:34:55.257449+00:00, run_end_date=2025-06-15 18:34:55.422928+00:00, run_duration=0.165479, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=8, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 18:34:51.497588+00:00, queued_by_job_id=1, pid=76126
2025-06-15 22:34:56,045 ERROR - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 18:14:19+00:00: manual__2025-06-15T18:14:19+00:00, state:running, queued_at: 2025-06-15 18:14:19.750442+00:00. externally triggered: True> failed
2025-06-15 22:34:56,046 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 18:14:19+00:00, run_id=manual__2025-06-15T18:14:19+00:00, run_start_date=2025-06-15 18:14:23.554399+00:00, run_end_date=2025-06-15 18:34:56.046357+00:00, run_duration=1232.491958, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 18:14:19+00:00, data_interval_end=2025-06-15 18:14:19+00:00, dag_hash=49470461074b2fc44874e252bd37a03b
2025-06-15 22:34:57,103 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:34:57,103 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:34:57,104 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:34:57,106 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-15 22:34:57,107 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T18:21:45+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-15 22:34:57,108 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:34:57,110 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:35:01,317 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T18:21:45+00:00', try_number=1, map_index=-1)
2025-06-15 22:35:01,326 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:35:00.616080+00:00, run_end_date=2025-06-15 18:35:00.790212+00:00, run_duration=0.174132, state=success, executor_state=success, try_number=1, max_tries=2, job_id=9, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2025-06-15 18:34:57.105602+00:00, queued_by_job_id=1, pid=76129
2025-06-15 22:35:01,386 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:35:01,387 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:35:01,388 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:35:01,390 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-15 22:35:01,391 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:21:45+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2025-06-15 22:35:01,392 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:35:01,394 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:35:05,721 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:21:45+00:00', try_number=1, map_index=-1)
2025-06-15 22:35:05,731 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:35:05.011492+00:00, run_end_date=2025-06-15 18:35:05.174558+00:00, run_duration=0.163066, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=10, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-06-15 18:35:01.389246+00:00, queued_by_job_id=1, pid=76141
2025-06-15 22:37:35,504 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:40:05,953 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:40:05,953 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:40:05,954 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:40:05,956 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:21:45+00:00', try_number=2, map_index=-1) to executor with priority 6 and queue default
2025-06-15 22:40:05,957 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:40:05,959 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:40:10,427 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:21:45+00:00', try_number=2, map_index=-1)
2025-06-15 22:40:10,437 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:40:09.681991+00:00, run_end_date=2025-06-15 18:40:09.846662+00:00, run_duration=0.164671, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=11, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 18:40:05.955491+00:00, queued_by_job_id=1, pid=76217
2025-06-15 22:42:35,565 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:45:10,548 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:45:10,549 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:45:10,549 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:45:10,552 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:21:45+00:00', try_number=3, map_index=-1) to executor with priority 7 and queue default
2025-06-15 22:45:10,553 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:45:10,554 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:45:15,091 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:21:45+00:00', try_number=3, map_index=-1)
2025-06-15 22:45:15,099 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:45:14.319118+00:00, run_end_date=2025-06-15 18:45:14.476665+00:00, run_duration=0.157547, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=12, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 18:45:10.550899+00:00, queued_by_job_id=1, pid=76414
2025-06-15 22:45:18,274 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:45:18,275 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:45:18,276 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:45:18,280 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-15 22:45:18,281 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:21:45+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-15 22:45:18,282 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:45:18,284 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:45:22,852 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:21:45+00:00', try_number=1, map_index=-1)
2025-06-15 22:45:22,861 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:45:22.137854+00:00, run_end_date=2025-06-15 18:45:22.304791+00:00, run_duration=0.166937, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=13, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 18:45:18.277773+00:00, queued_by_job_id=1, pid=76419
2025-06-15 22:47:35,573 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:50:22,915 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:50:22,916 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:50:22,917 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:50:22,919 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:21:45+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2025-06-15 22:50:22,920 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:50:22,922 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:50:27,565 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:21:45+00:00', try_number=2, map_index=-1)
2025-06-15 22:50:27,574 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:50:26.838251+00:00, run_end_date=2025-06-15 18:50:27.052209+00:00, run_duration=0.213958, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=14, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 18:50:22.918531+00:00, queued_by_job_id=1, pid=76529
2025-06-15 22:52:35,619 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 22:55:27,999 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:55:28,000 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 22:55:28,000 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T18:21:45+00:00 [scheduled]>
2025-06-15 22:55:28,003 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:21:45+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2025-06-15 22:55:28,004 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:55:28,006 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T18:21:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 22:55:32,618 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T18:21:45+00:00', try_number=3, map_index=-1)
2025-06-15 22:55:32,627 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T18:21:45+00:00, map_index=-1, run_start_date=2025-06-15 18:55:31.853005+00:00, run_end_date=2025-06-15 18:55:32.020638+00:00, run_duration=0.167633, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 18:55:28.001934+00:00, queued_by_job_id=1, pid=76664
2025-06-15 22:55:32,668 ERROR - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 18:21:45+00:00: manual__2025-06-15T18:21:45+00:00, state:running, queued_at: 2025-06-15 18:21:45.860217+00:00. externally triggered: True> failed
2025-06-15 22:55:32,669 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 18:21:45+00:00, run_id=manual__2025-06-15T18:21:45+00:00, run_start_date=2025-06-15 18:34:57.081638+00:00, run_end_date=2025-06-15 18:55:32.669858+00:00, run_duration=1235.58822, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 18:21:45+00:00, data_interval_end=2025-06-15 18:21:45+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-15 22:57:35,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:02:35,668 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:07:35,707 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:12:35,741 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:17:35,873 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:22:37,762 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:27:37,798 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:29:13,747 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:29:13,748 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:29:13,749 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-15 23:29:13,750 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:29:13,756 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-15 23:29:13,757 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-15 23:29:13,758 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-15 23:29:13,759 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:29:13,759 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-15 23:29:13,760 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:29:13,762 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:29:21,459 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:29:25,921 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-06-15 23:29:25,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-06-15 23:29:25,930 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=2025-06-15 19:29:13.824191+00:00, run_duration=None, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 19:29:13.751724+00:00, queued_by_job_id=1, pid=77584
2025-06-15 23:29:25,931 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=2025-06-15 19:29:13.756869+00:00, run_duration=None, state=success, executor_state=success, try_number=1, max_tries=2, job_id=None, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 19:29:13.751724+00:00, queued_by_job_id=1, pid=77584
2025-06-15 23:29:30,150 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:29:30,151 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:29:30,152 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:29:30,154 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-15 23:29:30,155 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-15 23:29:30,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:29:30,157 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:29:34,869 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-06-15 23:29:34,879 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:29:34.146357+00:00, run_end_date=2025-06-15 19:29:34.338767+00:00, run_duration=0.19241, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 19:29:30.153312+00:00, queued_by_job_id=1, pid=77635
2025-06-15 23:32:37,845 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:34:13,835 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:34:13,836 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:34:13,837 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:34:13,839 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2025-06-15 23:34:13,840 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:34:13,842 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:34:18,361 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T00:00:00+00:00', try_number=2, map_index=-1)
2025-06-15 23:34:18,372 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:34:17.658886+00:00, run_end_date=2025-06-15 19:34:17.818243+00:00, run_duration=0.159357, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=19, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 19:34:13.838381+00:00, queued_by_job_id=1, pid=77781
2025-06-15 23:35:03,621 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:35:03,622 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:35:03,622 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:35:03,625 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-15 23:35:03,625 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:35:03,627 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:35:07,977 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-06-15 23:35:07,985 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:35:07.270016+00:00, run_end_date=2025-06-15 19:35:07.440353+00:00, run_duration=0.170337, state=success, executor_state=success, try_number=1, max_tries=2, job_id=20, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 19:35:03.623902+00:00, queued_by_job_id=1, pid=77813
2025-06-15 23:35:08,038 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:35:08,039 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:35:08,040 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:35:08,042 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-15 23:35:08,042 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:35:08,044 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:35:12,380 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-06-15 23:35:12,389 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:35:11.674424+00:00, run_end_date=2025-06-15 19:35:11.837011+00:00, run_duration=0.162587, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=21, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 19:35:08.041045+00:00, queued_by_job_id=1, pid=77828
2025-06-15 23:37:37,895 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:40:12,853 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:40:12,854 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:40:12,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:40:12,857 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default
2025-06-15 23:40:12,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:40:12,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:40:17,154 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=2, map_index=-1)
2025-06-15 23:40:17,162 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:40:16.447988+00:00, run_end_date=2025-06-15 19:40:16.610565+00:00, run_duration=0.162577, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=22, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 19:40:12.855937+00:00, queued_by_job_id=1, pid=77987
2025-06-15 23:42:37,938 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:45:17,171 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:45:17,173 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:45:17,174 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:45:17,176 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=3, map_index=-1) to executor with priority 7 and queue default
2025-06-15 23:45:17,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:45:17,179 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:45:21,942 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T00:00:00+00:00', try_number=3, map_index=-1)
2025-06-15 23:45:21,951 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:45:21.197401+00:00, run_end_date=2025-06-15 19:45:21.363456+00:00, run_duration=0.166055, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=23, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 19:45:17.175461+00:00, queued_by_job_id=1, pid=78144
2025-06-15 23:45:25,114 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:45:25,114 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:45:25,115 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:45:25,117 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-15 23:45:25,118 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:45:25,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:45:29,643 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T00:00:00+00:00', try_number=1, map_index=-1)
2025-06-15 23:45:29,651 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:45:28.946556+00:00, run_end_date=2025-06-15 19:45:29.113711+00:00, run_duration=0.167155, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=24, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 19:45:25.116394+00:00, queued_by_job_id=1, pid=78158
2025-06-15 23:47:37,980 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:50:29,370 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:50:29,371 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:50:29,372 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:50:29,374 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2025-06-15 23:50:29,375 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:50:29,377 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:50:33,985 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T00:00:00+00:00', try_number=2, map_index=-1)
2025-06-15 23:50:33,994 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:50:33.271805+00:00, run_end_date=2025-06-15 19:50:33.436181+00:00, run_duration=0.164376, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 19:50:29.373667+00:00, queued_by_job_id=1, pid=78306
2025-06-15 23:52:38,024 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-15 23:55:33,475 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:55:33,476 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:55:33,477 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T00:00:00+00:00 [scheduled]>
2025-06-15 23:55:33,479 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T00:00:00+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2025-06-15 23:55:33,480 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:55:33,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:55:37,882 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T00:00:00+00:00', try_number=3, map_index=-1)
2025-06-15 23:55:37,891 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T00:00:00+00:00, map_index=-1, run_start_date=2025-06-15 19:55:37.132160+00:00, run_end_date=2025-06-15 19:55:37.297308+00:00, run_duration=0.165148, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=26, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 19:55:33.478155+00:00, queued_by_job_id=1, pid=78501
2025-06-15 23:55:37,934 ERROR - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 00:00:00+00:00: manual__2025-06-15T00:00:00+00:00, state:running, queued_at: None. externally triggered: False> failed
2025-06-15 23:55:37,936 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 00:00:00+00:00, run_id=manual__2025-06-15T00:00:00+00:00, run_start_date=2025-06-15 00:00:00+00:00, run_end_date=2025-06-15 19:55:37.935974+00:00, run_duration=71737.935974, state=failed, external_trigger=False, run_type=manual, data_interval_start=2025-06-15 00:00:00+00:00, data_interval_end=2025-06-15 00:00:00+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-15 23:55:38,991 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 23:55:38,991 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:55:38,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 23:55:38,994 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T18:14:19+00:00', try_number=2, map_index=-1) to executor with priority 8 and queue default
2025-06-15 23:55:38,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:55:38,997 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:55:43,429 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T18:14:19+00:00', try_number=2, map_index=-1)
2025-06-15 23:55:43,438 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 19:55:42.722274+00:00, run_end_date=2025-06-15 19:55:42.902134+00:00, run_duration=0.17986, state=success, executor_state=success, try_number=2, max_tries=3, job_id=27, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 19:55:38.993357+00:00, queued_by_job_id=1, pid=78504
2025-06-15 23:55:47,385 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 23:55:47,386 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-15 23:55:47,387 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T18:14:19+00:00 [scheduled]>
2025-06-15 23:55:47,389 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=4, map_index=-1) to executor with priority 7 and queue default
2025-06-15 23:55:47,390 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:55:47,392 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T18:14:19+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-15 23:55:51,879 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T18:14:19+00:00', try_number=4, map_index=-1)
2025-06-15 23:55:51,888 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T18:14:19+00:00, map_index=-1, run_start_date=2025-06-15 19:55:51.165389+00:00, run_end_date=2025-06-15 19:55:51.320484+00:00, run_duration=0.155095, state=up_for_retry, executor_state=success, try_number=4, max_tries=5, job_id=28, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 19:55:47.388569+00:00, queued_by_job_id=1, pid=78519
2025-06-15 23:56:27,346 ERROR - Exception when executing SchedulerJob._run_scheduler_loop
Traceback (most recent call last):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: dag_schedule_dataset_reference

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 855, in _execute
    self._run_scheduler_loop()
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 987, in _run_scheduler_loop
    num_queued_tis = self._do_scheduling(session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1061, in _do_scheduling
    self._create_dagruns_for_dags(guard, session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 91, in wrapped_function
    for attempt in run_with_db_retries(max_retries=retries, logger=logger, **retry_kwargs):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 438, in result
    return self.__get_result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 100, in wrapped_function
    return func(*args, **kwargs)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1127, in _create_dagruns_for_dags
    query, dataset_triggered_dag_info = DagModel.dags_needing_dagruns(session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/models/dag.py", line 3742, in dags_needing_dagruns
    for x in session.execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: dag_schedule_dataset_reference
[SQL: SELECT dag_schedule_dataset_reference.dag_id, max(dataset_dag_run_queue.created_at) AS last_queued_time, min(dataset_dag_run_queue.created_at) AS first_queued_time 
FROM dag_schedule_dataset_reference LEFT OUTER JOIN dataset_dag_run_queue ON dag_schedule_dataset_reference.dataset_id = dataset_dag_run_queue.dataset_id AND dag_schedule_dataset_reference.dag_id = dataset_dag_run_queue.target_dag_id GROUP BY dag_schedule_dataset_reference.dag_id 
HAVING count(*) = sum(CASE WHEN (dataset_dag_run_queue.target_dag_id IS NOT NULL) THEN ? ELSE ? END)]
[parameters: (1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
2025-06-15 23:56:27,409 INFO - Sending Signals.SIGTERM to group 75545. PIDs of all processes in the group: []
2025-06-15 23:56:27,409 INFO - Sending the signal Signals.SIGTERM to group 75545
2025-06-15 23:56:27,410 INFO - Sending the signal Signals.SIGTERM to process 75545 as process group is missing.
2025-06-15 23:56:27,411 INFO - Exited execute loop
2025-06-15 23:56:27,413 ERROR - Exception when running scheduler job
Traceback (most recent call last):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: dag_schedule_dataset_reference

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 393, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 422, in execute_job
    ret = execute_callable()
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 855, in _execute
    self._run_scheduler_loop()
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 987, in _run_scheduler_loop
    num_queued_tis = self._do_scheduling(session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1061, in _do_scheduling
    self._create_dagruns_for_dags(guard, session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 91, in wrapped_function
    for attempt in run_with_db_retries(max_retries=retries, logger=logger, **retry_kwargs):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 438, in result
    return self.__get_result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/retries.py", line 100, in wrapped_function
    return func(*args, **kwargs)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/scheduler_job_runner.py", line 1127, in _create_dagruns_for_dags
    query, dataset_triggered_dag_info = DagModel.dags_needing_dagruns(session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/models/dag.py", line 3742, in dags_needing_dagruns
    for x in session.execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: dag_schedule_dataset_reference
[SQL: SELECT dag_schedule_dataset_reference.dag_id, max(dataset_dag_run_queue.created_at) AS last_queued_time, min(dataset_dag_run_queue.created_at) AS first_queued_time 
FROM dag_schedule_dataset_reference LEFT OUTER JOIN dataset_dag_run_queue ON dag_schedule_dataset_reference.dataset_id = dataset_dag_run_queue.dataset_id AND dag_schedule_dataset_reference.dag_id = dataset_dag_run_queue.target_dag_id GROUP BY dag_schedule_dataset_reference.dag_id 
HAVING count(*) = sum(CASE WHEN (dataset_dag_run_queue.target_dag_id IS NOT NULL) THEN ? ELSE ? END)]
[parameters: (1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: job

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/cli/commands/scheduler_command.py", line 52, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 395, in run_job
    job.complete_execution(session=session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 240, in complete_execution
    Job._update_in_db(job=self, session=session)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/airflow/jobs/job.py", line 332, in _update_in_db
    session.merge(job)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/venv/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: job
[SQL: SELECT job.id AS job_id, job.dag_id AS job_dag_id, job.state AS job_state, job.job_type AS job_job_type, job.start_date AS job_start_date, job.end_date AS job_end_date, job.latest_heartbeat AS job_latest_heartbeat, job.executor_class AS job_executor_class, job.hostname AS job_hostname, job.unixname AS job_unixname 
FROM job 
WHERE job.id = ?]
[parameters: (1,)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
2025-06-15 23:58:26,070 INFO - Task context logging is enabled
2025-06-15 23:58:26,075 INFO - Loaded executor: SequentialExecutor
2025-06-15 23:58:26,186 INFO - Starting the scheduler
2025-06-15 23:58:26,187 INFO - Processing each file at most -1 times
2025-06-15 23:58:26,192 INFO - Launched DagFileProcessorManager with pid: 78694
2025-06-15 23:58:26,194 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:00:51,851 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2024-01-01 00:00:00+00:00: __airflow_temporary_run_2025-06-15T20:00:50.905171+00:00__, state:running, queued_at: 2025-06-15 20:00:50.905908+00:00. externally triggered: False> failed
2025-06-16 00:00:51,852 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2024-01-01 00:00:00+00:00, run_id=__airflow_temporary_run_2025-06-15T20:00:50.905171+00:00__, run_start_date=2025-06-15 20:00:51.814967+00:00, run_end_date=2025-06-15 20:00:51.852478+00:00, run_duration=0.037511, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-01-01 00:00:00+00:00, data_interval_end=2024-01-01 00:00:00+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 00:01:01,906 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2024-01-01 00:00:00+00:00: __airflow_temporary_run_2025-06-15T20:01:01.669908+00:00__, state:running, queued_at: 2025-06-15 20:01:01.670652+00:00. externally triggered: False> failed
2025-06-16 00:01:01,907 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2024-01-01 00:00:00+00:00, run_id=__airflow_temporary_run_2025-06-15T20:01:01.669908+00:00__, run_start_date=2025-06-15 20:01:01.895997+00:00, run_end_date=2025-06-15 20:01:01.907398+00:00, run_duration=0.011401, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-01-01 00:00:00+00:00, data_interval_end=2024-01-01 00:00:00+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 00:01:07,968 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2024-01-01 00:00:00+00:00: __airflow_temporary_run_2025-06-15T20:01:07.887195+00:00__, state:running, queued_at: 2025-06-15 20:01:07.887948+00:00. externally triggered: False> failed
2025-06-16 00:01:07,969 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2024-01-01 00:00:00+00:00, run_id=__airflow_temporary_run_2025-06-15T20:01:07.887195+00:00__, run_start_date=2025-06-15 20:01:07.954690+00:00, run_end_date=2025-06-15 20:01:07.969074+00:00, run_duration=0.014384, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-01-01 00:00:00+00:00, data_interval_end=2024-01-01 00:00:00+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 00:01:28,395 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:01:28,395 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:01:28,396 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:01:28,399 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 00:01:28,399 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T20:01:27+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 00:01:28,400 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:01:28,402 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:01:32,881 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T20:01:27+00:00', try_number=1, map_index=-1)
2025-06-16 00:01:32,894 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:01:32.173505+00:00, run_end_date=2025-06-15 20:01:32.352209+00:00, run_duration=0.178704, state=success, executor_state=success, try_number=1, max_tries=2, job_id=2, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 20:01:28.397697+00:00, queued_by_job_id=1, pid=79199
2025-06-16 00:01:32,948 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:01:32,949 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:01:32,949 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:01:32,951 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 00:01:32,952 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T20:01:27+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 00:01:32,953 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:01:32,955 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:01:37,403 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T20:01:27+00:00', try_number=1, map_index=-1)
2025-06-16 00:01:37,411 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:01:36.683439+00:00, run_end_date=2025-06-15 20:01:36.845206+00:00, run_duration=0.161767, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=3, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 20:01:32.950912+00:00, queued_by_job_id=1, pid=79211
2025-06-16 00:03:26,262 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:06:37,044 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:06:37,045 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:06:37,045 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:06:37,047 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T20:01:27+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default
2025-06-16 00:06:37,048 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:06:37,050 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:06:41,719 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T20:01:27+00:00', try_number=2, map_index=-1)
2025-06-16 00:06:41,728 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:06:41.019302+00:00, run_end_date=2025-06-15 20:06:41.186260+00:00, run_duration=0.166958, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=4, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 20:06:37.046798+00:00, queued_by_job_id=1, pid=79348
2025-06-16 00:08:26,314 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:11:41,803 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:11:41,804 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:11:41,804 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:11:41,806 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T20:01:27+00:00', try_number=3, map_index=-1) to executor with priority 7 and queue default
2025-06-16 00:11:41,807 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:11:41,808 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:11:46,010 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T20:01:27+00:00', try_number=3, map_index=-1)
2025-06-16 00:11:46,018 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:11:45.325337+00:00, run_end_date=2025-06-15 20:11:45.474493+00:00, run_duration=0.149156, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=5, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 20:11:41.805694+00:00, queued_by_job_id=1, pid=79418
2025-06-16 00:11:49,187 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:11:49,187 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:11:49,188 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:11:49,190 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-16 00:11:49,191 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T20:01:27+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 00:11:49,192 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:11:49,194 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:11:53,044 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T20:01:27+00:00', try_number=1, map_index=-1)
2025-06-16 00:11:53,052 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:11:52.375494+00:00, run_end_date=2025-06-15 20:11:52.534346+00:00, run_duration=0.158852, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 20:11:49.189700+00:00, queued_by_job_id=1, pid=79421
2025-06-16 00:13:26,435 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:16:52,745 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:16:52,745 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:16:52,746 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:16:52,748 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T20:01:27+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2025-06-16 00:16:52,749 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:16:52,751 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:16:56,840 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T20:01:27+00:00', try_number=2, map_index=-1)
2025-06-16 00:16:56,848 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:16:56.190968+00:00, run_end_date=2025-06-15 20:16:56.339260+00:00, run_duration=0.148292, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 20:16:52.747330+00:00, queued_by_job_id=1, pid=79480
2025-06-16 00:18:26,492 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:21:56,572 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:21:56,573 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 00:21:56,574 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T20:01:27+00:00 [scheduled]>
2025-06-16 00:21:56,576 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T20:01:27+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2025-06-16 00:21:56,576 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:21:56,578 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T20:01:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 00:22:00,630 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T20:01:27+00:00', try_number=3, map_index=-1)
2025-06-16 00:22:00,638 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T20:01:27+00:00, map_index=-1, run_start_date=2025-06-15 20:21:59.922533+00:00, run_end_date=2025-06-15 20:22:00.080525+00:00, run_duration=0.157992, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=8, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 20:21:56.574980+00:00, queued_by_job_id=1, pid=79540
2025-06-16 00:22:00,677 ERROR - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 20:01:27+00:00: manual__2025-06-15T20:01:27+00:00, state:running, queued_at: 2025-06-15 20:01:27.666488+00:00. externally triggered: True> failed
2025-06-16 00:22:00,678 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 20:01:27+00:00, run_id=manual__2025-06-15T20:01:27+00:00, run_start_date=2025-06-15 20:01:28.373266+00:00, run_end_date=2025-06-15 20:22:00.678461+00:00, run_duration=1232.305195, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 20:01:27+00:00, data_interval_end=2025-06-15 20:01:27+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 00:23:26,536 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:28:26,612 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:33:26,657 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:38:26,705 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:43:26,766 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:48:26,812 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:53:26,859 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 00:58:27,724 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:03:29,141 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:08:30,354 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:13:31,625 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:18:29,615 INFO - Exiting gracefully upon receiving signal 15
2025-06-16 01:18:30,221 INFO - Sending Signals.SIGTERM to group 78694. PIDs of all processes in the group: []
2025-06-16 01:18:30,222 INFO - Sending the signal Signals.SIGTERM to group 78694
2025-06-16 01:18:30,223 INFO - Sending the signal Signals.SIGTERM to process 78694 as process group is missing.
2025-06-16 01:18:30,226 INFO - Sending Signals.SIGTERM to group 78694. PIDs of all processes in the group: []
2025-06-16 01:18:30,226 INFO - Sending the signal Signals.SIGTERM to group 78694
2025-06-16 01:18:30,227 INFO - Sending the signal Signals.SIGTERM to process 78694 as process group is missing.
2025-06-16 01:18:30,228 INFO - Exited execute loop
2025-06-16 01:20:16,029 INFO - Task context logging is enabled
2025-06-16 01:20:16,035 INFO - Loaded executor: SequentialExecutor
2025-06-16 01:20:16,142 INFO - Starting the scheduler
2025-06-16 01:20:16,143 INFO - Processing each file at most -1 times
2025-06-16 01:20:16,150 INFO - Launched DagFileProcessorManager with pid: 80457
2025-06-16 01:20:16,153 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:20:38,514 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:20:38,515 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:20:38,516 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:20:38,518 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 01:20:38,519 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T21:20:37+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 01:20:38,519 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:20:38,521 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:20:42,961 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T21:20:37+00:00', try_number=1, map_index=-1)
2025-06-16 01:20:42,973 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T21:20:37+00:00, map_index=-1, run_start_date=2025-06-15 21:20:42.267470+00:00, run_end_date=2025-06-15 21:20:42.449995+00:00, run_duration=0.182525, state=success, executor_state=success, try_number=1, max_tries=2, job_id=10, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 21:20:38.516989+00:00, queued_by_job_id=9, pid=80490
2025-06-16 01:20:43,020 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:20:43,021 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:20:43,021 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:20:43,023 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 01:20:43,024 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:20:37+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 01:20:43,025 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:20:43,026 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:20:47,489 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:20:37+00:00', try_number=1, map_index=-1)
2025-06-16 01:20:47,498 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T21:20:37+00:00, map_index=-1, run_start_date=2025-06-15 21:20:46.745149+00:00, run_end_date=2025-06-15 21:20:46.933427+00:00, run_duration=0.188278, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=11, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 21:20:43.022588+00:00, queued_by_job_id=9, pid=80503
2025-06-16 01:25:02,666 INFO - Exiting gracefully upon receiving signal 15
2025-06-16 01:25:03,199 INFO - Sending Signals.SIGTERM to group 80457. PIDs of all processes in the group: []
2025-06-16 01:25:03,200 INFO - Sending the signal Signals.SIGTERM to group 80457
2025-06-16 01:25:03,201 INFO - Sending the signal Signals.SIGTERM to process 80457 as process group is missing.
2025-06-16 01:25:03,203 INFO - Sending Signals.SIGTERM to group 80457. PIDs of all processes in the group: []
2025-06-16 01:25:03,204 INFO - Sending the signal Signals.SIGTERM to group 80457
2025-06-16 01:25:03,205 INFO - Sending the signal Signals.SIGTERM to process 80457 as process group is missing.
2025-06-16 01:25:03,206 INFO - Exited execute loop
2025-06-16 01:25:40,318 INFO - Task context logging is enabled
2025-06-16 01:25:40,323 INFO - Loaded executor: SequentialExecutor
2025-06-16 01:25:40,430 INFO - Starting the scheduler
2025-06-16 01:25:40,431 INFO - Processing each file at most -1 times
2025-06-16 01:25:40,437 INFO - Launched DagFileProcessorManager with pid: 80791
2025-06-16 01:25:40,440 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:25:47,700 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:25:47,700 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:25:47,701 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:25:47,704 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:20:37+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default
2025-06-16 01:25:47,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:25:47,706 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:25:52,372 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:20:37+00:00', try_number=2, map_index=-1)
2025-06-16 01:25:52,385 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T21:20:37+00:00, map_index=-1, run_start_date=2025-06-15 21:25:51.669606+00:00, run_end_date=2025-06-15 21:25:51.854013+00:00, run_duration=0.184407, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=13, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 21:25:47.702535+00:00, queued_by_job_id=12, pid=80815
2025-06-16 01:30:40,440 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:30:53,660 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:30:53,661 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:30:53,662 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:30:53,664 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:20:37+00:00', try_number=3, map_index=-1) to executor with priority 7 and queue default
2025-06-16 01:30:53,665 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:30:53,667 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:30:58,184 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:20:37+00:00', try_number=3, map_index=-1)
2025-06-16 01:30:58,193 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T21:20:37+00:00, map_index=-1, run_start_date=2025-06-15 21:30:57.424738+00:00, run_end_date=2025-06-15 21:30:57.586090+00:00, run_duration=0.161352, state=failed, executor_state=success, try_number=3, max_tries=2, job_id=14, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 21:30:53.663122+00:00, queued_by_job_id=12, pid=80977
2025-06-16 01:31:01,374 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:31:01,374 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:31:01,375 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:31:01,377 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-16 01:31:01,378 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T21:20:37+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 01:31:01,379 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:31:01,381 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:31:05,746 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T21:20:37+00:00', try_number=1, map_index=-1)
2025-06-16 01:31:05,755 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T21:20:37+00:00, map_index=-1, run_start_date=2025-06-15 21:31:05.032665+00:00, run_end_date=2025-06-15 21:31:05.204042+00:00, run_duration=0.171377, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 21:31:01.376773+00:00, queued_by_job_id=12, pid=80981
2025-06-16 01:35:17,165 INFO - Exiting gracefully upon receiving signal 15
2025-06-16 01:35:17,736 INFO - Sending Signals.SIGTERM to group 80791. PIDs of all processes in the group: []
2025-06-16 01:35:17,737 INFO - Sending the signal Signals.SIGTERM to group 80791
2025-06-16 01:35:17,738 INFO - Sending the signal Signals.SIGTERM to process 80791 as process group is missing.
2025-06-16 01:35:17,741 INFO - Sending Signals.SIGTERM to group 80791. PIDs of all processes in the group: []
2025-06-16 01:35:17,742 INFO - Sending the signal Signals.SIGTERM to group 80791
2025-06-16 01:35:17,743 INFO - Sending the signal Signals.SIGTERM to process 80791 as process group is missing.
2025-06-16 01:35:17,743 INFO - Exited execute loop
2025-06-16 01:36:15,007 INFO - Task context logging is enabled
2025-06-16 01:36:15,012 INFO - Loaded executor: SequentialExecutor
2025-06-16 01:36:15,119 INFO - Starting the scheduler
2025-06-16 01:36:15,120 INFO - Processing each file at most -1 times
2025-06-16 01:36:15,126 INFO - Launched DagFileProcessorManager with pid: 81147
2025-06-16 01:36:15,129 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:36:20,918 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:36:20,919 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:36:20,920 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T21:20:37+00:00 [scheduled]>
2025-06-16 01:36:20,923 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T21:20:37+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2025-06-16 01:36:20,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:36:20,926 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:42:03,379 INFO - Exiting gracefully upon receiving signal 15
2025-06-16 01:42:04,095 INFO - Sending Signals.SIGTERM to group 81147. PIDs of all processes in the group: []
2025-06-16 01:42:04,096 INFO - Sending the signal Signals.SIGTERM to group 81147
2025-06-16 01:42:04,097 INFO - Sending the signal Signals.SIGTERM to process 81147 as process group is missing.
2025-06-16 01:42:04,108 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T21:20:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:42:08,371 INFO - Sending Signals.SIGTERM to group 81147. PIDs of all processes in the group: []
2025-06-16 01:42:08,372 INFO - Sending the signal Signals.SIGTERM to group 81147
2025-06-16 01:42:08,373 INFO - Sending the signal Signals.SIGTERM to process 81147 as process group is missing.
2025-06-16 01:42:08,374 INFO - Exited execute loop
2025-06-16 01:43:55,913 INFO - Task context logging is enabled
2025-06-16 01:43:55,918 INFO - Loaded executor: SequentialExecutor
2025-06-16 01:43:56,033 INFO - Starting the scheduler
2025-06-16 01:43:56,035 INFO - Processing each file at most -1 times
2025-06-16 01:43:56,042 INFO - Launched DagFileProcessorManager with pid: 81549
2025-06-16 01:43:56,045 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:45:54,216 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:45:54,217 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:45:54,217 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:45:54,220 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 01:45:54,222 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 01:45:54,222 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:45:54,224 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:45:59,576 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:45:59,589 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:45:58.824122+00:00, run_end_date=2025-06-15 21:45:59.042610+00:00, run_duration=0.218488, state=success, executor_state=success, try_number=1, max_tries=2, job_id=2, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 21:45:54.219070+00:00, queued_by_job_id=1, pid=81677
2025-06-16 01:45:59,657 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:45:59,658 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:45:59,658 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:45:59,661 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 01:45:59,662 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 01:45:59,663 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:45:59,665 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:05,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:46:05,129 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:46:04.292119+00:00, run_end_date=2025-06-15 21:46:04.578064+00:00, run_duration=0.285945, state=success, executor_state=success, try_number=1, max_tries=2, job_id=3, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 21:45:59.660246+00:00, queued_by_job_id=1, pid=81694
2025-06-16 01:46:05,185 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T21:44:10+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:46:05,186 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:46:05,186 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 01:46:05,187 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T21:44:10+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:46:05,190 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 01:46:05,191 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 01:46:05,192 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 01:46:05,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:05,194 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 01:46:05,195 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:05,197 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:10,539 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:16,290 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:46:16,293 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:46:16,302 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:46:15.111265+00:00, run_end_date=2025-06-15 21:46:15.729186+00:00, run_duration=0.617921, state=success, executor_state=success, try_number=1, max_tries=2, job_id=5, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 21:46:05.188875+00:00, queued_by_job_id=1, pid=81709
2025-06-16 01:46:16,304 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:46:09.691195+00:00, run_end_date=2025-06-15 21:46:09.985066+00:00, run_duration=0.293871, state=success, executor_state=success, try_number=1, max_tries=2, job_id=4, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 21:46:05.188875+00:00, queued_by_job_id=1, pid=81699
2025-06-16 01:46:21,153 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:46:21,154 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:46:21,155 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:46:21,158 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 01:46:21,159 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 01:46:21,160 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:21,162 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:35,825 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:46:35,837 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:46:25.814966+00:00, run_end_date=2025-06-15 21:46:35.172439+00:00, run_duration=9.357473, state=success, executor_state=success, try_number=1, max_tries=2, job_id=6, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 21:46:21.157059+00:00, queued_by_job_id=1, pid=81724
2025-06-16 01:46:35,917 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:46:35,918 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:46:35,919 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:46:35,922 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 01:46:35,924 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 01:46:35,925 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:35,928 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:46:43,540 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:46:43,552 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:46:41.943723+00:00, run_end_date=None, run_duration=None, state=running, executor_state=success, try_number=1, max_tries=2, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 21:46:35.921173+00:00, queued_by_job_id=1, pid=81751
2025-06-16 01:46:45,922 WARNING - Failing (1) jobs without heartbeat after 2025-06-15 21:41:45.918721+00:00
2025-06-16 01:46:45,924 ERROR - Detected zombie job: {'full_filepath': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags/ml_pipeline_dag.py', 'processor_subdir': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags', 'msg': "{'DAG Id': 'breast_cancer_ml_pipeline', 'Task Id': 'evaluate_model', 'Run Id': 'manual__2025-06-15T21:44:10+00:00', 'Hostname': 'yuriys-macbook-pro.local'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x10efe5730>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
2025-06-16 01:48:56,115 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:51:51,930 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:51:51,932 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:51:51,933 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:51:51,935 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T21:44:10+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2025-06-16 01:51:51,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:51:51,939 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:52:01,793 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T21:44:10+00:00', try_number=2, map_index=-1)
2025-06-16 01:52:01,805 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:51:57.330070+00:00, run_end_date=2025-06-15 21:52:01.180444+00:00, run_duration=3.850374, state=success, executor_state=success, try_number=2, max_tries=2, job_id=8, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 21:51:51.934277+00:00, queued_by_job_id=1, pid=81902
2025-06-16 01:52:07,643 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:52:07,645 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 01:52:07,646 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T21:44:10+00:00 [scheduled]>
2025-06-16 01:52:07,649 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 01:52:07,650 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 01:52:07,651 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:52:07,654 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T21:44:10+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 01:57:20,452 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T21:44:10+00:00', try_number=1, map_index=-1)
2025-06-16 01:57:20,461 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T21:44:10+00:00, map_index=-1, run_start_date=2025-06-15 21:52:13.305439+00:00, run_end_date=None, run_duration=None, state=running, executor_state=success, try_number=1, max_tries=2, job_id=9, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 21:52:07.647767+00:00, queued_by_job_id=1, pid=81939
2025-06-16 01:57:20,474 ERROR - DagFileProcessorManager (PID=81549) last sent a heartbeat 312.87 seconds ago! Restarting it
2025-06-16 01:57:20,496 INFO - Sending Signals.SIGTERM to group 81549. PIDs of all processes in the group: [81549]
2025-06-16 01:57:20,497 INFO - Sending the signal Signals.SIGTERM to group 81549
2025-06-16 01:57:21,202 INFO - Process psutil.Process(pid=81549, status='terminated', exitcode=0, started='01:43:56') (81549) terminated with exit code 0
2025-06-16 01:57:21,210 INFO - Launched DagFileProcessorManager with pid: 82110
2025-06-16 01:57:21,239 WARNING - Failing (1) jobs without heartbeat after 2025-06-15 21:52:21.236186+00:00
2025-06-16 01:57:21,240 ERROR - Detected zombie job: {'full_filepath': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags/ml_pipeline_dag.py', 'processor_subdir': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags', 'msg': "{'DAG Id': 'breast_cancer_ml_pipeline', 'Task Id': 'save_results', 'Run Id': 'manual__2025-06-15T21:44:10+00:00', 'Hostname': 'yuriys-macbook-pro.local'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x117da5e20>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
2025-06-16 01:57:21,252 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 01:59:38,408 INFO - Task context logging is enabled
2025-06-16 01:59:38,413 INFO - Loaded executor: SequentialExecutor
2025-06-16 01:59:38,517 INFO - Starting the scheduler
2025-06-16 01:59:38,518 INFO - Processing each file at most -1 times
2025-06-16 01:59:38,524 INFO - Launched DagFileProcessorManager with pid: 82237
2025-06-16 01:59:38,527 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:01:24,556 INFO - Task context logging is enabled
2025-06-16 02:01:24,561 INFO - Loaded executor: SequentialExecutor
2025-06-16 02:01:24,667 INFO - Starting the scheduler
2025-06-16 02:01:24,668 INFO - Processing each file at most -1 times
2025-06-16 02:01:24,674 INFO - Launched DagFileProcessorManager with pid: 82401
2025-06-16 02:01:24,677 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:02:06,060 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:06,061 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:02:06,062 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:06,066 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 02:02:06,068 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 02:02:06,068 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:06,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:11,129 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:02:11,141 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:10.401189+00:00, run_end_date=2025-06-15 22:02:10.581699+00:00, run_duration=0.18051, state=success, executor_state=success, try_number=1, max_tries=2, job_id=12, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 22:02:06.063803+00:00, queued_by_job_id=11, pid=82448
2025-06-16 02:02:11,199 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:11,201 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:02:11,201 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:11,204 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 02:02:11,205 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 02:02:11,206 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:11,208 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:16,006 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:02:16,016 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:14.895369+00:00, run_end_date=2025-06-15 22:02:15.137370+00:00, run_duration=0.242001, state=success, executor_state=success, try_number=1, max_tries=2, job_id=13, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 22:02:11.203044+00:00, queued_by_job_id=11, pid=82461
2025-06-16 02:02:16,069 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:02:04+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:16,070 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:02:16,071 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 02:02:16,072 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:02:04+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:16,074 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 02:02:16,075 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 02:02:16,076 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 02:02:16,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:16,078 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:02:16,079 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:16,080 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:20,712 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:25,427 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:02:25,429 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:02:25,437 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:24.383216+00:00, run_end_date=2025-06-15 22:02:24.861227+00:00, run_duration=0.478011, state=success, executor_state=success, try_number=1, max_tries=2, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:02:16.073379+00:00, queued_by_job_id=11, pid=82476
2025-06-16 02:02:25,438 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:19.915661+00:00, run_end_date=2025-06-15 22:02:20.145157+00:00, run_duration=0.229496, state=success, executor_state=success, try_number=1, max_tries=2, job_id=14, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 22:02:16.073379+00:00, queued_by_job_id=11, pid=82471
2025-06-16 02:02:25,497 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:25,497 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:02:25,498 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:25,501 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 02:02:25,502 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 02:02:25,502 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:25,504 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:36,356 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:02:36,365 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:29.380778+00:00, run_end_date=2025-06-15 22:02:35.807610+00:00, run_duration=6.426832, state=success, executor_state=success, try_number=1, max_tries=2, job_id=16, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 22:02:25.499432+00:00, queued_by_job_id=11, pid=82480
2025-06-16 02:02:40,447 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:40,448 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:02:40,449 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:40,451 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 02:02:40,452 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 02:02:40,453 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:40,455 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:47,173 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:02:47,182 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:44.188220+00:00, run_end_date=2025-06-15 22:02:46.580558+00:00, run_duration=2.392338, state=success, executor_state=success, try_number=1, max_tries=2, job_id=17, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 22:02:40.450170+00:00, queued_by_job_id=11, pid=82508
2025-06-16 02:02:47,249 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:47,250 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:02:47,251 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:02:04+00:00 [scheduled]>
2025-06-16 02:02:47,254 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 02:02:47,255 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 02:02:47,256 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:02:47,258 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:02:04+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:05:37,899 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:02:04+00:00', try_number=1, map_index=-1)
2025-06-16 02:05:37,909 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T22:02:04+00:00, map_index=-1, run_start_date=2025-06-15 22:02:51.632227+00:00, run_end_date=None, run_duration=None, state=running, executor_state=success, try_number=1, max_tries=2, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 22:02:47.252913+00:00, queued_by_job_id=11, pid=82519
2025-06-16 02:05:37,922 ERROR - DagFileProcessorManager (PID=82401) last sent a heartbeat 170.71 seconds ago! Restarting it
2025-06-16 02:05:37,947 INFO - Sending Signals.SIGTERM to group 82401. PIDs of all processes in the group: [82401]
2025-06-16 02:05:37,949 INFO - Sending the signal Signals.SIGTERM to group 82401
2025-06-16 02:05:38,752 INFO - Process psutil.Process(pid=82401, status='terminated', exitcode=0, started='02:01:24') (82401) terminated with exit code 0
2025-06-16 02:05:38,762 INFO - Launched DagFileProcessorManager with pid: 82582
2025-06-16 02:05:38,788 WARNING - Failing (1) jobs without heartbeat after 2025-06-15 22:00:38.783825+00:00
2025-06-16 02:05:38,789 ERROR - Detected zombie job: {'full_filepath': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags/ml_pipeline_dag.py', 'processor_subdir': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags', 'msg': "{'DAG Id': 'breast_cancer_ml_pipeline', 'Task Id': 'save_results', 'Run Id': 'manual__2025-06-15T22:02:04+00:00', 'Hostname': 'yuriys-macbook-pro.local'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x10de88370>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
2025-06-16 02:06:24,746 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:06:24,750 INFO - Marked 1 SchedulerJob instances as failed
2025-06-16 02:11:28,386 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:16:28,428 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:28,429 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:16:28,430 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:28,431 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 02:16:28,432 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 02:16:28,433 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:28,435 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:33,108 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:16:33,116 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:16:32.365051+00:00, run_end_date=2025-06-15 22:16:32.540968+00:00, run_duration=0.175917, state=success, executor_state=success, try_number=1, max_tries=2, job_id=12, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 22:16:28.431003+00:00, queued_by_job_id=11, pid=83131
2025-06-16 02:16:33,135 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:16:37,213 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:37,214 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:16:37,215 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:37,217 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 02:16:37,218 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 02:16:37,219 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:37,221 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:41,799 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:16:41,809 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:16:41.009982+00:00, run_end_date=2025-06-15 22:16:41.240907+00:00, run_duration=0.230925, state=success, executor_state=success, try_number=1, max_tries=2, job_id=13, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 22:16:37.216354+00:00, queued_by_job_id=11, pid=83151
2025-06-16 02:16:41,867 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:16:27+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:41,868 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:16:41,868 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 02:16:41,869 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:16:27+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:41,871 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 02:16:41,872 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 02:16:41,873 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 02:16:41,873 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:41,874 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:16:41,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:41,877 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:46,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:50,938 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:16:50,940 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:16:50,948 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:16:49.972156+00:00, run_end_date=2025-06-15 22:16:50.430731+00:00, run_duration=0.458575, state=success, executor_state=success, try_number=1, max_tries=2, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:16:41.870390+00:00, queued_by_job_id=11, pid=83162
2025-06-16 02:16:50,949 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:16:45.516200+00:00, run_end_date=2025-06-15 22:16:45.737876+00:00, run_duration=0.221676, state=success, executor_state=success, try_number=1, max_tries=2, job_id=14, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 22:16:41.870390+00:00, queued_by_job_id=11, pid=83159
2025-06-16 02:16:51,009 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:51,010 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:16:51,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:16:51,012 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 02:16:51,013 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 02:16:51,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:16:51,016 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:17:01,409 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:17:01,418 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:16:54.741384+00:00, run_end_date=2025-06-15 22:17:00.853956+00:00, run_duration=6.112572, state=success, executor_state=success, try_number=1, max_tries=2, job_id=16, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 22:16:51.011977+00:00, queued_by_job_id=11, pid=83172
2025-06-16 02:17:01,472 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:17:01,473 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:17:01,474 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:17:01,476 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 02:17:01,476 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 02:17:01,477 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:17:01,479 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:17:08,200 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:17:08,209 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:17:05.289861+00:00, run_end_date=2025-06-15 22:17:07.653028+00:00, run_duration=2.363167, state=success, executor_state=success, try_number=1, max_tries=2, job_id=17, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 22:17:01.475051+00:00, queued_by_job_id=11, pid=83201
2025-06-16 02:17:12,345 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:17:12,346 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:17:12,346 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:16:27+00:00 [scheduled]>
2025-06-16 02:17:12,348 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 02:17:12,349 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 02:17:12,350 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:17:12,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:25:48,030 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:16:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']' died with <Signals.SIGKILL: 9>..
2025-06-16 02:25:48,033 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:16:27+00:00', try_number=1, map_index=-1)
2025-06-16 02:25:48,042 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T22:16:27+00:00, map_index=-1, run_start_date=2025-06-15 22:17:16.007611+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=2, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 22:17:12.347795+00:00, queued_by_job_id=11, pid=83222
2025-06-16 02:25:48,055 ERROR - DagFileProcessorManager (PID=82582) last sent a heartbeat 515.74 seconds ago! Restarting it
2025-06-16 02:25:48,076 INFO - Sending Signals.SIGTERM to group 82582. PIDs of all processes in the group: [82582]
2025-06-16 02:25:48,077 INFO - Sending the signal Signals.SIGTERM to group 82582
2025-06-16 02:25:48,662 INFO - Process psutil.Process(pid=82582, status='terminated', exitcode=0, started='02:05:38') (82582) terminated with exit code 0
2025-06-16 02:25:48,669 INFO - Launched DagFileProcessorManager with pid: 83482
2025-06-16 02:25:48,697 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:30:48,015 WARNING - Failing (1) jobs without heartbeat after 2025-06-15 22:25:48.012662+00:00
2025-06-16 02:30:48,016 ERROR - Detected zombie job: {'full_filepath': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags/ml_pipeline_dag.py', 'processor_subdir': '/Users/yuriy.samorodov/Documents// 2/Data Engineering/Exam/ml-pipeline-project/dags', 'msg': "{'DAG Id': 'breast_cancer_ml_pipeline', 'Task Id': 'save_results', 'Run Id': 'manual__2025-06-15T22:16:27+00:00', 'Hostname': 'yuriys-macbook-pro.local'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x116e00fa0>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
2025-06-16 02:30:52,090 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:35:29,078 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:29,079 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:35:29,079 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:29,081 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 02:35:29,082 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 02:35:29,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:29,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:33,746 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:35:33,755 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:35:33.024188+00:00, run_end_date=2025-06-15 22:35:33.199684+00:00, run_duration=0.175496, state=success, executor_state=success, try_number=1, max_tries=2, job_id=12, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 22:35:29.080788+00:00, queued_by_job_id=11, pid=83825
2025-06-16 02:35:33,809 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:33,810 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:35:33,810 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:33,813 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 02:35:33,814 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 02:35:33,815 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:33,817 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:38,403 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:35:38,414 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:35:37.466556+00:00, run_end_date=2025-06-15 22:35:37.750115+00:00, run_duration=0.283559, state=success, executor_state=success, try_number=1, max_tries=2, job_id=13, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 22:35:33.811927+00:00, queued_by_job_id=11, pid=83838
2025-06-16 02:35:38,460 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:35:28+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:38,461 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:35:38,461 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 02:35:38,462 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:35:28+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:38,464 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 02:35:38,465 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 02:35:38,465 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 02:35:38,466 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:38,467 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:35:38,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:38,470 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:43,494 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:48,578 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:35:48,580 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:35:48,588 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:35:47.449064+00:00, run_end_date=2025-06-15 22:35:47.995411+00:00, run_duration=0.546347, state=success, executor_state=success, try_number=1, max_tries=2, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:35:38.463346+00:00, queued_by_job_id=11, pid=83847
2025-06-16 02:35:48,589 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:35:42.659037+00:00, run_end_date=2025-06-15 22:35:42.895706+00:00, run_duration=0.236669, state=success, executor_state=success, try_number=1, max_tries=2, job_id=14, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 22:35:38.463346+00:00, queued_by_job_id=11, pid=83841
2025-06-16 02:35:48,644 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:48,645 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:35:48,645 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:35:48,647 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 02:35:48,648 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 02:35:48,649 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:48,651 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:35:59,460 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:35:59,470 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:35:52.355664+00:00, run_end_date=2025-06-15 22:35:58.926876+00:00, run_duration=6.571212, state=success, executor_state=success, try_number=1, max_tries=2, job_id=16, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 22:35:48.646830+00:00, queued_by_job_id=11, pid=83856
2025-06-16 02:35:59,490 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:36:03,462 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:36:03,463 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:36:03,464 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:36:03,466 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 02:36:03,467 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 02:36:03,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:36:03,470 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:36:10,202 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:36:10,211 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:36:07.356978+00:00, run_end_date=2025-06-15 22:36:09.637040+00:00, run_duration=2.280062, state=success, executor_state=success, try_number=1, max_tries=2, job_id=17, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 22:36:03.465725+00:00, queued_by_job_id=11, pid=83888
2025-06-16 02:36:10,269 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:36:10,270 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:36:10,271 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:35:28+00:00 [scheduled]>
2025-06-16 02:36:10,273 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 02:36:10,274 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 02:36:10,275 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:36:10,277 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:40:48,124 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:35:28+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']' died with <Signals.SIGKILL: 9>..
2025-06-16 02:40:48,136 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:35:28+00:00', try_number=1, map_index=-1)
2025-06-16 02:40:48,145 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T22:35:28+00:00, map_index=-1, run_start_date=2025-06-15 22:36:13.974796+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=2, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 22:36:10.272482+00:00, queued_by_job_id=11, pid=83895
2025-06-16 02:40:48,158 ERROR - DagFileProcessorManager (PID=83482) last sent a heartbeat 277.92 seconds ago! Restarting it
2025-06-16 02:40:48,179 INFO - Sending Signals.SIGTERM to group 83482. PIDs of all processes in the group: [83482]
2025-06-16 02:40:48,180 INFO - Sending the signal Signals.SIGTERM to group 83482
2025-06-16 02:40:48,805 INFO - Process psutil.Process(pid=83482, status='terminated', exitcode=0, started='02:25:48') (83482) terminated with exit code 0
2025-06-16 02:40:48,812 INFO - Launched DagFileProcessorManager with pid: 83996
2025-06-16 02:40:59,528 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:42:05,763 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 22:35:28+00:00: manual__2025-06-15T22:35:28+00:00, state:running, queued_at: 2025-06-15 22:35:28.187430+00:00. externally triggered: True> failed
2025-06-16 02:42:05,764 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 22:35:28+00:00, run_id=manual__2025-06-15T22:35:28+00:00, run_start_date=2025-06-15 22:35:29.060083+00:00, run_end_date=2025-06-15 22:42:05.764475+00:00, run_duration=396.704392, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 22:35:28+00:00, data_interval_end=2025-06-15 22:35:28+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 02:42:53,058 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:42:53,058 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:42:53,059 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:42:53,061 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 02:42:53,062 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 02:42:53,063 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:42:53,065 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:42:58,065 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:42:58,074 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:42:57.342082+00:00, run_end_date=2025-06-15 22:42:57.520612+00:00, run_duration=0.17853, state=success, executor_state=success, try_number=1, max_tries=2, job_id=19, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 22:42:53.060395+00:00, queued_by_job_id=11, pid=84059
2025-06-16 02:42:58,128 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:42:58,129 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:42:58,129 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:42:58,131 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 02:42:58,132 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 02:42:58,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:42:58,134 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:02,914 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:43:02,923 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:43:02.107281+00:00, run_end_date=2025-06-15 22:43:02.372639+00:00, run_duration=0.265358, state=success, executor_state=success, try_number=1, max_tries=2, job_id=20, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 22:42:58.130639+00:00, queued_by_job_id=11, pid=84075
2025-06-16 02:43:02,974 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:42:52+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:02,974 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:43:02,975 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 02:43:02,976 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:42:52+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:02,978 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 02:43:02,979 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 02:43:02,980 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 02:43:02,980 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:02,981 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:43:02,982 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:02,983 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:08,022 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:12,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:43:12,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:43:12,931 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:43:11.888170+00:00, run_end_date=2025-06-15 22:43:12.371384+00:00, run_duration=0.483214, state=success, executor_state=success, try_number=1, max_tries=2, job_id=22, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:43:02.977300+00:00, queued_by_job_id=11, pid=84087
2025-06-16 02:43:12,932 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:43:07.070953+00:00, run_end_date=2025-06-15 22:43:07.432811+00:00, run_duration=0.361858, state=success, executor_state=success, try_number=1, max_tries=2, job_id=21, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 22:43:02.977300+00:00, queued_by_job_id=11, pid=84078
2025-06-16 02:43:16,930 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:16,931 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:43:16,931 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:16,934 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 02:43:16,935 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 02:43:16,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:16,938 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:27,424 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:43:27,433 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:43:20.799994+00:00, run_end_date=2025-06-15 22:43:26.766073+00:00, run_duration=5.966079, state=success, executor_state=success, try_number=1, max_tries=2, job_id=23, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 22:43:16.933163+00:00, queued_by_job_id=11, pid=84095
2025-06-16 02:43:27,500 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:27,501 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:43:27,501 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:27,503 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 02:43:27,504 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 02:43:27,505 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:27,507 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:34,129 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:43:34,137 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:43:31.202508+00:00, run_end_date=2025-06-15 22:43:33.536861+00:00, run_duration=2.334353, state=success, executor_state=success, try_number=1, max_tries=2, job_id=24, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 22:43:27.502794+00:00, queued_by_job_id=11, pid=84120
2025-06-16 02:43:34,190 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:34,191 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:43:34,192 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:42:52+00:00 [scheduled]>
2025-06-16 02:43:34,194 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 02:43:34,195 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 02:43:34,195 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:43:34,197 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:50:09,922 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:42:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']' died with <Signals.SIGKILL: 9>..
2025-06-16 02:50:09,926 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:42:52+00:00', try_number=1, map_index=-1)
2025-06-16 02:50:09,936 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T22:42:52+00:00, map_index=-1, run_start_date=2025-06-15 22:43:37.858560+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=2, job_id=25, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 22:43:34.193231+00:00, queued_by_job_id=11, pid=84127
2025-06-16 02:50:09,949 ERROR - DagFileProcessorManager (PID=83996) last sent a heartbeat 395.78 seconds ago! Restarting it
2025-06-16 02:50:09,973 INFO - Sending Signals.SIGTERM to group 83996. PIDs of all processes in the group: [83996]
2025-06-16 02:50:09,974 INFO - Sending the signal Signals.SIGTERM to group 83996
2025-06-16 02:50:10,638 INFO - Process psutil.Process(pid=83996, status='terminated', exitcode=0, started='02:40:48') (83996) terminated with exit code 0
2025-06-16 02:50:10,645 INFO - Launched DagFileProcessorManager with pid: 84291
2025-06-16 02:50:10,675 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:51:26,632 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 22:42:52+00:00: manual__2025-06-15T22:42:52+00:00, state:running, queued_at: 2025-06-15 22:42:52.032653+00:00. externally triggered: True> failed
2025-06-16 02:51:26,634 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 22:42:52+00:00, run_id=manual__2025-06-15T22:42:52+00:00, run_start_date=2025-06-15 22:42:53.038958+00:00, run_end_date=2025-06-15 22:51:26.633956+00:00, run_duration=513.594998, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 22:42:52+00:00, data_interval_end=2025-06-15 22:42:52+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 02:51:30,814 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:30,815 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:51:30,816 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:30,818 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 02:51:30,819 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 02:51:30,820 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:30,822 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:35,466 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:51:35,475 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T22:51:29+00:00, map_index=-1, run_start_date=2025-06-15 22:51:34.746061+00:00, run_end_date=2025-06-15 22:51:34.922632+00:00, run_duration=0.176571, state=success, executor_state=success, try_number=1, max_tries=2, job_id=26, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 22:51:30.817627+00:00, queued_by_job_id=11, pid=84355
2025-06-16 02:51:35,526 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:35,527 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:51:35,528 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:35,530 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 02:51:35,531 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 02:51:35,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:35,533 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:39,943 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:51:39,953 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T22:51:29+00:00, map_index=-1, run_start_date=2025-06-15 22:51:39.133069+00:00, run_end_date=2025-06-15 22:51:39.370367+00:00, run_duration=0.237298, state=success, executor_state=success, try_number=1, max_tries=2, job_id=27, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 22:51:35.529366+00:00, queued_by_job_id=11, pid=84370
2025-06-16 02:51:40,005 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:51:29+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:40,006 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:51:40,007 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 02:51:40,008 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:51:29+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:40,011 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 02:51:40,012 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 02:51:40,013 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 02:51:40,014 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:40,015 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:51:40,016 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:40,019 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:44,446 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:49,314 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:51:49,316 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:51:49,323 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T22:51:29+00:00, map_index=-1, run_start_date=2025-06-15 22:51:48.276417+00:00, run_end_date=2025-06-15 22:51:48.782085+00:00, run_duration=0.505668, state=success, executor_state=success, try_number=1, max_tries=2, job_id=29, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:51:40.010356+00:00, queued_by_job_id=11, pid=84379
2025-06-16 02:51:49,325 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T22:51:29+00:00, map_index=-1, run_start_date=2025-06-15 22:51:43.662780+00:00, run_end_date=2025-06-15 22:51:43.884325+00:00, run_duration=0.221545, state=success, executor_state=success, try_number=1, max_tries=2, job_id=28, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 22:51:40.010356+00:00, queued_by_job_id=11, pid=84374
2025-06-16 02:51:49,384 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:49,385 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:51:49,385 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:51:49,387 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 02:51:49,388 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 02:51:49,389 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:51:49,391 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:52:00,250 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:52:00,261 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T22:51:29+00:00, map_index=-1, run_start_date=2025-06-15 22:51:53.044780+00:00, run_end_date=2025-06-15 22:51:59.672517+00:00, run_duration=6.627737, state=success, executor_state=success, try_number=1, max_tries=2, job_id=30, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 22:51:49.386863+00:00, queued_by_job_id=11, pid=84387
2025-06-16 02:52:04,790 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:52:04,791 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:52:04,792 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:52:04,794 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 02:52:04,795 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 02:52:04,796 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:52:04,798 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:52:12,366 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:52:12,375 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T22:51:29+00:00, map_index=-1, run_start_date=2025-06-15 22:52:09.033820+00:00, run_end_date=2025-06-15 22:52:11.789266+00:00, run_duration=2.755446, state=success, executor_state=success, try_number=1, max_tries=2, job_id=31, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 22:52:04.793262+00:00, queued_by_job_id=11, pid=84415
2025-06-16 02:52:12,442 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:52:12,443 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:52:12,444 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:51:29+00:00 [scheduled]>
2025-06-16 02:52:12,447 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 02:52:12,448 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 02:52:12,449 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:52:12,451 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:57:20,754 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:51:29+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']' died with <Signals.SIGKILL: 9>..
2025-06-16 02:57:20,757 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:51:29+00:00', try_number=1, map_index=-1)
2025-06-16 02:57:20,775 ERROR - DagFileProcessorManager (PID=84291) last sent a heartbeat 308.36 seconds ago! Restarting it
2025-06-16 02:57:20,799 INFO - Sending Signals.SIGTERM to group 84291. PIDs of all processes in the group: [84291]
2025-06-16 02:57:20,801 INFO - Sending the signal Signals.SIGTERM to group 84291
2025-06-16 02:57:21,465 INFO - Process psutil.Process(pid=84291, status='terminated', exitcode=0, started='02:50:10') (84291) terminated with exit code 0
2025-06-16 02:57:21,472 INFO - Launched DagFileProcessorManager with pid: 84519
2025-06-16 02:57:21,503 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 02:57:28,467 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 22:51:29+00:00: manual__2025-06-15T22:51:29+00:00, state:running, queued_at: 2025-06-15 22:51:29.032410+00:00. externally triggered: True> failed
2025-06-16 02:57:28,468 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 22:51:29+00:00, run_id=manual__2025-06-15T22:51:29+00:00, run_start_date=2025-06-15 22:51:30.792472+00:00, run_end_date=2025-06-15 22:57:28.468358+00:00, run_duration=357.675886, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 22:51:29+00:00, data_interval_end=2025-06-15 22:51:29+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 02:57:56,767 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:57:56,768 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:57:56,768 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:57:56,770 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 02:57:56,771 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 02:57:56,772 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:57:56,774 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:01,351 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:01,360 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:00.623426+00:00, run_end_date=2025-06-15 22:58:00.803557+00:00, run_duration=0.180131, state=success, executor_state=success, try_number=1, max_tries=2, job_id=33, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 22:57:56.769745+00:00, queued_by_job_id=11, pid=84553
2025-06-16 02:58:05,458 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:05,459 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:58:05,460 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:05,463 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 02:58:05,464 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 02:58:05,465 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:05,467 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:10,024 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:10,033 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:09.221592+00:00, run_end_date=2025-06-15 22:58:09.457499+00:00, run_duration=0.235907, state=success, executor_state=success, try_number=1, max_tries=2, job_id=34, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 22:58:05.461726+00:00, queued_by_job_id=11, pid=84575
2025-06-16 02:58:10,099 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:57:55+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:10,100 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:58:10,100 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 02:58:10,101 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T22:57:55+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:10,103 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 02:58:10,104 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 02:58:10,104 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 02:58:10,105 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:10,106 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:58:10,106 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:10,108 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:14,941 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:20,192 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:20,194 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:20,202 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:19.152425+00:00, run_end_date=2025-06-15 22:58:19.675081+00:00, run_duration=0.522656, state=success, executor_state=success, try_number=1, max_tries=2, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:58:10.102457+00:00, queued_by_job_id=11, pid=84586
2025-06-16 02:58:20,203 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:14.152006+00:00, run_end_date=2025-06-15 22:58:14.390720+00:00, run_duration=0.238714, state=success, executor_state=success, try_number=1, max_tries=2, job_id=35, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 22:58:10.102457+00:00, queued_by_job_id=11, pid=84581
2025-06-16 02:58:20,253 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:20,254 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:58:20,255 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:20,257 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 02:58:20,258 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 02:58:20,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:20,260 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:32,165 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:32,175 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:24.198476+00:00, run_end_date=2025-06-15 22:58:31.524852+00:00, run_duration=7.326376, state=success, executor_state=success, try_number=1, max_tries=2, job_id=37, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 22:58:20.256352+00:00, queued_by_job_id=11, pid=84591
2025-06-16 02:58:32,257 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:32,258 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:58:32,259 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:32,262 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 02:58:32,264 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 02:58:32,265 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:32,267 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:42,076 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:42,088 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:37.703251+00:00, run_end_date=2025-06-15 22:58:41.277935+00:00, run_duration=3.574684, state=success, executor_state=success, try_number=1, max_tries=2, job_id=38, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 22:58:32.260718+00:00, queued_by_job_id=11, pid=84613
2025-06-16 02:58:47,966 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:47,968 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:58:47,969 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:47,971 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 02:58:47,973 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 02:58:47,974 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:47,976 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:54,089 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:54,100 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:53.141515+00:00, run_end_date=2025-06-15 22:58:53.373183+00:00, run_duration=0.231668, state=success, executor_state=success, try_number=1, max_tries=2, job_id=39, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 22:58:47.970358+00:00, queued_by_job_id=11, pid=84623
2025-06-16 02:58:54,167 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:54,168 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 02:58:54,169 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T22:57:55+00:00 [scheduled]>
2025-06-16 02:58:54,172 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-16 02:58:54,173 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 02:58:54,174 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:54,176 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T22:57:55+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 02:58:59,789 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T22:57:55+00:00', try_number=1, map_index=-1)
2025-06-16 02:58:59,800 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T22:57:55+00:00, map_index=-1, run_start_date=2025-06-15 22:58:59.016286+00:00, run_end_date=2025-06-15 22:58:59.225286+00:00, run_duration=0.209, state=success, executor_state=success, try_number=1, max_tries=2, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 22:58:54.170906+00:00, queued_by_job_id=11, pid=84627
2025-06-16 02:58:59,842 INFO - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 22:57:55+00:00: manual__2025-06-15T22:57:55+00:00, state:running, queued_at: 2025-06-15 22:57:55.065478+00:00. externally triggered: True> successful
2025-06-16 02:58:59,844 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 22:57:55+00:00, run_id=manual__2025-06-15T22:57:55+00:00, run_start_date=2025-06-15 22:57:56.746512+00:00, run_end_date=2025-06-15 22:58:59.844034+00:00, run_duration=63.097522, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 22:57:55+00:00, data_interval_end=2025-06-15 22:57:55+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 03:02:21,540 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 03:07:21,579 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 03:10:48,045 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:10:48,046 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:10:48,046 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:10:48,048 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 03:10:48,049 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 03:10:48,050 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:10:48,052 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:10:52,595 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1)
2025-06-16 03:10:52,604 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T23:10:47+00:00, map_index=-1, run_start_date=2025-06-15 23:10:51.868282+00:00, run_end_date=2025-06-15 23:10:52.048090+00:00, run_duration=0.179808, state=success, executor_state=success, try_number=1, max_tries=2, job_id=41, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 23:10:48.047851+00:00, queued_by_job_id=11, pid=84859
2025-06-16 03:10:52,659 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:10:52,659 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:10:52,660 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:10:52,662 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 03:10:52,663 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 03:10:52,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:10:52,665 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:10:57,186 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1)
2025-06-16 03:10:57,194 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T23:10:47+00:00, map_index=-1, run_start_date=2025-06-15 23:10:56.371448+00:00, run_end_date=2025-06-15 23:10:56.637019+00:00, run_duration=0.265571, state=success, executor_state=success, try_number=1, max_tries=2, job_id=42, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 23:10:52.661418+00:00, queued_by_job_id=11, pid=84872
2025-06-16 03:10:57,241 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T23:10:47+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:10:57,242 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:10:57,242 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 03:10:57,243 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T23:10:47+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:10:57,245 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 03:10:57,246 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 03:10:57,247 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 03:10:57,247 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:10:57,248 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 03:10:57,249 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:10:57,251 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:11:01,888 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:11:06,547 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1)
2025-06-16 03:11:06,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1)
2025-06-16 03:11:06,557 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T23:10:47+00:00, map_index=-1, run_start_date=2025-06-15 23:11:05.503545+00:00, run_end_date=2025-06-15 23:11:05.995535+00:00, run_duration=0.49199, state=success, executor_state=success, try_number=1, max_tries=2, job_id=44, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 23:10:57.244388+00:00, queued_by_job_id=11, pid=84890
2025-06-16 03:11:06,558 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T23:10:47+00:00, map_index=-1, run_start_date=2025-06-15 23:11:01.089659+00:00, run_end_date=2025-06-15 23:11:01.357149+00:00, run_duration=0.26749, state=success, executor_state=success, try_number=1, max_tries=2, job_id=43, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 23:10:57.244388+00:00, queued_by_job_id=11, pid=84885
2025-06-16 03:11:10,530 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:11:10,531 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:11:10,532 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:11:10,534 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 03:11:10,535 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 03:11:10,536 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:11:10,538 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:11:20,511 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:10:47+00:00', try_number=1, map_index=-1)
2025-06-16 03:11:20,521 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T23:10:47+00:00, map_index=-1, run_start_date=2025-06-15 23:11:14.361393+00:00, run_end_date=2025-06-15 23:11:19.916655+00:00, run_duration=5.555262, state=up_for_retry, executor_state=success, try_number=1, max_tries=2, job_id=45, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 23:11:10.533208+00:00, queued_by_job_id=11, pid=84903
2025-06-16 03:12:21,627 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 03:16:20,183 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:16:20,184 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:16:20,185 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:10:47+00:00 [scheduled]>
2025-06-16 03:16:20,188 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:10:47+00:00', try_number=2, map_index=-1) to executor with priority 4 and queue default
2025-06-16 03:16:20,189 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:16:20,191 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:10:47+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:16:24,983 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:10:47+00:00', try_number=2, map_index=-1)
2025-06-16 03:16:24,993 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T23:10:47+00:00, map_index=-1, run_start_date=2025-06-15 23:16:24.058044+00:00, run_end_date=2025-06-15 23:16:24.377938+00:00, run_duration=0.319894, state=up_for_retry, executor_state=success, try_number=2, max_tries=2, job_id=46, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 23:16:20.186868+00:00, queued_by_job_id=11, pid=85094
2025-06-16 03:17:24,664 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 03:19:14,712 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 23:10:47+00:00: manual__2025-06-15T23:10:47+00:00, state:running, queued_at: 2025-06-15 23:10:47.574811+00:00. externally triggered: True> failed
2025-06-16 03:19:14,713 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 23:10:47+00:00, run_id=manual__2025-06-15T23:10:47+00:00, run_start_date=2025-06-15 23:10:48.026692+00:00, run_end_date=2025-06-15 23:19:14.713445+00:00, run_duration=506.686753, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 23:10:47+00:00, data_interval_end=2025-06-15 23:10:47+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 03:19:15,775 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:15,776 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:15,778 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:15,780 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 03:19:15,781 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 03:19:15,782 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:15,784 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:20,925 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:20,934 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:20.150117+00:00, run_end_date=2025-06-15 23:19:20.365570+00:00, run_duration=0.215453, state=success, executor_state=success, try_number=1, max_tries=2, job_id=47, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 23:19:15.779609+00:00, queued_by_job_id=11, pid=85178
2025-06-16 03:19:20,991 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:20,991 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:20,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:20,994 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 03:19:20,995 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 03:19:20,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:20,997 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:25,484 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:25,493 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:24.606399+00:00, run_end_date=2025-06-15 23:19:24.879165+00:00, run_duration=0.272766, state=success, executor_state=success, try_number=1, max_tries=2, job_id=48, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 23:19:20.993460+00:00, queued_by_job_id=11, pid=85190
2025-06-16 03:19:25,543 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T23:14:05+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:25,544 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:25,545 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 03:19:25,545 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T23:14:05+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:25,547 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 03:19:25,548 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 03:19:25,549 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 03:19:25,549 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:25,550 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 03:19:25,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:25,553 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:30,253 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:35,317 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:35,319 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:35,328 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:34.046411+00:00, run_end_date=2025-06-15 23:19:34.667396+00:00, run_duration=0.620985, state=success, executor_state=success, try_number=1, max_tries=2, job_id=50, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 23:19:25.546551+00:00, queued_by_job_id=11, pid=85204
2025-06-16 03:19:35,329 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:29.404094+00:00, run_end_date=2025-06-15 23:19:29.683732+00:00, run_duration=0.279638, state=success, executor_state=success, try_number=1, max_tries=2, job_id=49, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 23:19:25.546551+00:00, queued_by_job_id=11, pid=85194
2025-06-16 03:19:35,392 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:35,393 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:35,394 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:35,396 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 03:19:35,398 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 03:19:35,398 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:35,401 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:40,109 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:40,118 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:39.307207+00:00, run_end_date=2025-06-15 23:19:39.541405+00:00, run_duration=0.234198, state=success, executor_state=success, try_number=1, max_tries=2, job_id=51, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 23:19:35.395561+00:00, queued_by_job_id=11, pid=85212
2025-06-16 03:19:44,354 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:44,356 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:44,357 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:44,360 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 03:19:44,361 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 03:19:44,362 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:44,364 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:50,889 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:50,899 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:48.130874+00:00, run_end_date=2025-06-15 23:19:50.264792+00:00, run_duration=2.133918, state=success, executor_state=success, try_number=1, max_tries=2, job_id=52, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 23:19:44.358688+00:00, queued_by_job_id=11, pid=85219
2025-06-16 03:19:50,962 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:50,962 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:50,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:50,965 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 03:19:50,966 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 03:19:50,966 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:50,968 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:55,668 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:19:55,678 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:54.759280+00:00, run_end_date=2025-06-15 23:19:54.991453+00:00, run_duration=0.232173, state=success, executor_state=success, try_number=1, max_tries=2, job_id=53, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 23:19:50.964338+00:00, queued_by_job_id=11, pid=85229
2025-06-16 03:19:55,723 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:55,724 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:19:55,725 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T23:14:05+00:00 [scheduled]>
2025-06-16 03:19:55,727 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-16 03:19:55,728 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 03:19:55,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:19:55,731 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T23:14:05+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:20:00,750 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T23:14:05+00:00', try_number=1, map_index=-1)
2025-06-16 03:20:00,759 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T23:14:05+00:00, map_index=-1, run_start_date=2025-06-15 23:19:59.959692+00:00, run_end_date=2025-06-15 23:20:00.129462+00:00, run_duration=0.16977, state=success, executor_state=success, try_number=1, max_tries=2, job_id=54, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 23:19:55.726139+00:00, queued_by_job_id=11, pid=85238
2025-06-16 03:20:00,803 INFO - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 23:14:05+00:00: manual__2025-06-15T23:14:05+00:00, state:running, queued_at: 2025-06-15 23:14:05.113835+00:00. externally triggered: True> successful
2025-06-16 03:20:00,804 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 23:14:05+00:00, run_id=manual__2025-06-15T23:14:05+00:00, run_start_date=2025-06-15 23:19:15.750452+00:00, run_end_date=2025-06-15 23:20:00.804517+00:00, run_duration=45.054065, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 23:14:05+00:00, data_interval_end=2025-06-15 23:14:05+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 03:21:11,290 ERROR - Task deadlock (no runnable tasks); marking run <DagRun breast_cancer_ml_pipeline @ 2024-01-01 00:00:00+00:00: __airflow_temporary_run_2025-06-15T23:21:11.245652+00:00__, state:running, queued_at: 2025-06-15 23:21:11.246391+00:00. externally triggered: False> failed
2025-06-16 03:21:11,291 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2024-01-01 00:00:00+00:00, run_id=__airflow_temporary_run_2025-06-15T23:21:11.245652+00:00__, run_start_date=2025-06-15 23:21:11.274588+00:00, run_end_date=2025-06-15 23:21:11.291848+00:00, run_duration=0.01726, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-01-01 00:00:00+00:00, data_interval_end=2024-01-01 00:00:00+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 03:21:28,636 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:28,637 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:21:28,637 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.health_check manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:28,640 WARNING - cannot record scheduled_duration for task health_check because previous state change time has not been saved
2025-06-16 03:21:28,641 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2025-06-16 03:21:28,641 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:28,643 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'health_check', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:33,612 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='health_check', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:21:33,622 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=health_check, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:21:32.830573+00:00, run_end_date=2025-06-15 23:21:33.028747+00:00, run_duration=0.198174, state=success, executor_state=success, try_number=1, max_tries=2, job_id=55, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-06-15 23:21:28.639026+00:00, queued_by_job_id=11, pid=85291
2025-06-16 03:21:37,796 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:37,797 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:21:37,798 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.load_and_validate_data manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:37,801 WARNING - cannot record scheduled_duration for task load_and_validate_data because previous state change time has not been saved
2025-06-16 03:21:37,802 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2025-06-16 03:21:37,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:37,806 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'load_and_validate_data', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:42,427 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='load_and_validate_data', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:21:42,436 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=load_and_validate_data, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:21:41.607906+00:00, run_end_date=2025-06-15 23:21:41.869181+00:00, run_duration=0.261275, state=success, executor_state=success, try_number=1, max_tries=2, job_id=56, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-06-15 23:21:37.800037+00:00, queued_by_job_id=11, pid=85313
2025-06-16 03:21:42,506 INFO - 2 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T23:21:27+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:42,507 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:21:42,508 INFO - DAG breast_cancer_ml_pipeline has 1/16 running and queued tasks
2025-06-16 03:21:42,508 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.preprocess_data manual__2025-06-15T23:21:27+00:00 [scheduled]>
	<TaskInstance: breast_cancer_ml_pipeline.data_quality_check manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:42,511 WARNING - cannot record scheduled_duration for task preprocess_data because previous state change time has not been saved
2025-06-16 03:21:42,511 WARNING - cannot record scheduled_duration for task data_quality_check because previous state change time has not been saved
2025-06-16 03:21:42,512 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2025-06-16 03:21:42,513 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:42,514 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 03:21:42,514 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:42,516 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'preprocess_data', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:47,237 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'data_quality_check', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:52,097 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='preprocess_data', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:21:52,099 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='data_quality_check', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:21:52,106 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=data_quality_check, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:21:51.091061+00:00, run_end_date=2025-06-15 23:21:51.576082+00:00, run_duration=0.485021, state=success, executor_state=success, try_number=1, max_tries=2, job_id=58, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 23:21:42.509856+00:00, queued_by_job_id=11, pid=85323
2025-06-16 03:21:52,107 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=preprocess_data, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:21:46.419241+00:00, run_end_date=2025-06-15 23:21:46.700798+00:00, run_duration=0.281557, state=success, executor_state=success, try_number=1, max_tries=2, job_id=57, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-06-15 23:21:42.509856+00:00, queued_by_job_id=11, pid=85318
2025-06-16 03:21:52,153 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:52,154 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:21:52,154 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.train_model manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:52,156 WARNING - cannot record scheduled_duration for task train_model because previous state change time has not been saved
2025-06-16 03:21:52,157 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2025-06-16 03:21:52,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:52,160 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'train_model', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:56,931 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='train_model', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:21:56,940 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=train_model, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:21:56.109080+00:00, run_end_date=2025-06-15 23:21:56.355279+00:00, run_duration=0.246199, state=success, executor_state=success, try_number=1, max_tries=2, job_id=59, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-06-15 23:21:52.155674+00:00, queued_by_job_id=11, pid=85326
2025-06-16 03:21:56,992 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:56,992 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:21:56,993 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.evaluate_model manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:21:56,995 WARNING - cannot record scheduled_duration for task evaluate_model because previous state change time has not been saved
2025-06-16 03:21:56,996 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2025-06-16 03:21:56,997 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:21:56,999 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'evaluate_model', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:22:03,407 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='evaluate_model', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:22:03,416 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=evaluate_model, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:22:00.694193+00:00, run_end_date=2025-06-15 23:22:02.837273+00:00, run_duration=2.14308, state=success, executor_state=success, try_number=1, max_tries=2, job_id=60, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-06-15 23:21:56.994540+00:00, queued_by_job_id=11, pid=85330
2025-06-16 03:22:03,470 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:22:03,471 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:22:03,471 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.save_results manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:22:03,473 WARNING - cannot record scheduled_duration for task save_results because previous state change time has not been saved
2025-06-16 03:22:03,474 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2025-06-16 03:22:03,475 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:22:03,477 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'save_results', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:22:07,962 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='save_results', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:22:07,971 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=save_results, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:22:07.194991+00:00, run_end_date=2025-06-15 23:22:07.412757+00:00, run_duration=0.217766, state=success, executor_state=success, try_number=1, max_tries=2, job_id=61, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-06-15 23:22:03.472877+00:00, queued_by_job_id=11, pid=85334
2025-06-16 03:22:12,057 INFO - 1 tasks up for execution:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:22:12,058 INFO - DAG breast_cancer_ml_pipeline has 0/16 running and queued tasks
2025-06-16 03:22:12,059 INFO - Setting the following tasks to queued state:
	<TaskInstance: breast_cancer_ml_pipeline.cleanup manual__2025-06-15T23:21:27+00:00 [scheduled]>
2025-06-16 03:22:12,061 WARNING - cannot record scheduled_duration for task cleanup because previous state change time has not been saved
2025-06-16 03:22:12,063 INFO - Sending TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2025-06-16 03:22:12,064 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:22:12,066 INFO - Executing command: ['airflow', 'tasks', 'run', 'breast_cancer_ml_pipeline', 'cleanup', 'manual__2025-06-15T23:21:27+00:00', '--local', '--subdir', 'DAGS_FOLDER/ml_pipeline_dag.py']
2025-06-16 03:22:16,494 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='breast_cancer_ml_pipeline', task_id='cleanup', run_id='manual__2025-06-15T23:21:27+00:00', try_number=1, map_index=-1)
2025-06-16 03:22:16,503 INFO - TaskInstance Finished: dag_id=breast_cancer_ml_pipeline, task_id=cleanup, run_id=manual__2025-06-15T23:21:27+00:00, map_index=-1, run_start_date=2025-06-15 23:22:15.769661+00:00, run_end_date=2025-06-15 23:22:15.933875+00:00, run_duration=0.164214, state=success, executor_state=success, try_number=1, max_tries=2, job_id=62, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-06-15 23:22:12.060373+00:00, queued_by_job_id=11, pid=85340
2025-06-16 03:22:16,547 INFO - Marking run <DagRun breast_cancer_ml_pipeline @ 2025-06-15 23:21:27+00:00: manual__2025-06-15T23:21:27+00:00, state:running, queued_at: 2025-06-15 23:21:27.714919+00:00. externally triggered: True> successful
2025-06-16 03:22:16,548 INFO - DagRun Finished: dag_id=breast_cancer_ml_pipeline, execution_date=2025-06-15 23:21:27+00:00, run_id=manual__2025-06-15T23:21:27+00:00, run_start_date=2025-06-15 23:21:28.616763+00:00, run_end_date=2025-06-15 23:22:16.548215+00:00, run_duration=47.931452, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-06-15 23:21:27+00:00, data_interval_end=2025-06-15 23:21:27+00:00, dag_hash=f728d68f06f7c1828d6c70e998a94482
2025-06-16 03:22:24,702 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 03:27:24,740 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-06-16 03:29:17,075 INFO - Exiting gracefully upon receiving signal 15
2025-06-16 03:29:17,655 INFO - Sending Signals.SIGTERM to group 84519. PIDs of all processes in the group: []
2025-06-16 03:29:17,656 INFO - Sending the signal Signals.SIGTERM to group 84519
2025-06-16 03:29:17,657 INFO - Sending the signal Signals.SIGTERM to process 84519 as process group is missing.
2025-06-16 03:29:17,660 INFO - Sending Signals.SIGTERM to group 84519. PIDs of all processes in the group: []
2025-06-16 03:29:17,661 INFO - Sending the signal Signals.SIGTERM to group 84519
2025-06-16 03:29:17,661 INFO - Sending the signal Signals.SIGTERM to process 84519 as process group is missing.
2025-06-16 03:29:17,662 INFO - Exited execute loop
2025-06-16 03:34:54,341 INFO - Task context logging is enabled
2025-06-16 03:34:54,347 INFO - Loaded executor: LocalExecutor
2025-06-16 06:09:16,509 INFO - Task context logging is enabled
2025-06-16 06:09:16,516 INFO - Loaded executor: LocalExecutor
2025-06-16 06:14:21,074 INFO - Task context logging is enabled
2025-06-16 06:14:21,083 INFO - Loaded executor: LocalExecutor
2025-06-16 06:16:05,986 INFO - Task context logging is enabled
2025-06-16 06:16:05,994 INFO - Loaded executor: LocalExecutor
2025-06-16 06:17:21,989 INFO - Task context logging is enabled
2025-06-16 06:17:21,996 INFO - Loaded executor: LocalExecutor
