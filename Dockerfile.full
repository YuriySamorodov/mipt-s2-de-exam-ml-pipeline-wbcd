# Dockerfile для тестирования полного requirements.txt
# Базируется на официальном образе Apache Airflow

FROM apache/airflow:2.8.1-python3.10

# Переключаемся на root для установки системных пакетов
USER root

# Установка системных зависимостей
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Возвращаемся к пользователю airflow
USER airflow

# Установка Python зависимостей из полного файла
COPY requirements.txt /tmp/requirements.txt
RUN pip install --upgrade pip \
    && pip install --no-cache-dir -r /tmp/requirements.txt

# Копирование файлов проекта
COPY --chown=airflow:root ./dags /opt/airflow/dags
COPY --chown=airflow:root ./etl /opt/airflow/etl
COPY --chown=airflow:root ./config /opt/airflow/config
COPY --chown=airflow:root ./data /opt/airflow/data

# Создание директорий для результатов
RUN mkdir -p /opt/airflow/results/models \
             /opt/airflow/results/metrics \
             /opt/airflow/results/plots \
             /opt/airflow/logs

# Установка переменных окружения
ENV AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
ENV AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins
ENV AIRFLOW__CORE__LOAD_EXAMPLES=False
ENV AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080
ENV AIRFLOW__LOGGING__BASE_LOG_FOLDER=/opt/airflow/logs

# Проверка здоровья контейнера
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=5 \
    CMD airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}" \
        || curl --fail http://localhost:8080/health || exit 1

# Экспонируем порт веб-сервера
EXPOSE 8080

# Добавление меток для идентификации
LABEL ml-pipeline.component="airflow"
LABEL ml-pipeline.version="1.0"
LABEL ml-pipeline.description="Apache Airflow для ML Pipeline диагностики рака молочной железы"

# Команда по умолчанию (может быть переопределена в docker-compose)
CMD ["webserver"]
